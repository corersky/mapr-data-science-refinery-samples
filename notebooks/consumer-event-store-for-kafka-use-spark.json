{"paragraphs":[{"text":"%md\n#### The notebook contains samples code for the comsumer using the Spark interpreter for accessing MapR Event Store for Kafka.\n\n[MapR Data Science Refinery Documentation](https://mapr.com/docs/61/Zeppelin/ZeppelinMapRESSpark.html)\n\n#### Pre-requisistes\n\nBefore running the code configure the [Spark interpreter](https://mapr.com/docs/61/Zeppelin/ConfigureSparkInterpreter.html#task_t1d_4yj_qbb). Make sure to follow the steps described in the [Spark Jobs](https://mapr.com/docs/61/Zeppelin/ConfigureSparkInterpreter.html#task_t1d_4yj_qbb__section_zwx_pdk_qbb) section to allow Spark jobs to run in parallel.","user":"mapr","dateUpdated":"2019-05-02T06:19:13-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556803109503_1209699443","id":"20190502-061829_958550742","dateCreated":"2019-05-02T06:18:29-0700","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:533","dateFinished":"2019-05-02T06:19:13-0700","dateStarted":"2019-05-02T06:19:13-0700","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>The notebook contains samples code for the comsumer using the Spark interpreter for accessing MapR Event Store for Kafka.</h4>\n<p><a href=\"https://mapr.com/docs/61/Zeppelin/ZeppelinMapRESSpark.html\">MapR Data Science Refinery Documentation</a></p>\n<h4>Pre-requisistes</h4>\n<p>Before running the code configure the <a href=\"https://mapr.com/docs/61/Zeppelin/ConfigureSparkInterpreter.html#task_t1d_4yj_qbb\">Spark interpreter</a>. Make sure to follow the steps described in the <a href=\"https://mapr.com/docs/61/Zeppelin/ConfigureSparkInterpreter.html#task_t1d_4yj_qbb__section_zwx_pdk_qbb\">Spark Jobs</a> section to allow Spark jobs to run in parallel.</p>\n</div>"}]}},{"text":"%spark\n\nimport org.apache.kafka.clients.consumer.ConsumerConfig\n\nimport org.apache.spark.SparkConf\nimport org.apache.spark.streaming.{Seconds, StreamingContext}\nimport org.apache.spark.streaming.kafka09.{ConsumerStrategies, KafkaUtils, LocationStrategies}        \n\nval ssc = new StreamingContext(sc, Seconds(1))\n\nval topicsSet = Set(\"/streaming_test/test_stream:test_topic\")\nval kafkaParams = Map[String, String](\n  ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG -> \"localhost:9092\",\n  ConsumerConfig.GROUP_ID_CONFIG -> \"none\",\n  ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG ->\n    \"org.apache.kafka.common.serialization.StringDeserializer\",\n  ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG ->\n    \"org.apache.kafka.common.serialization.StringDeserializer\",\n  ConsumerConfig.AUTO_OFFSET_RESET_CONFIG -> \"latest\",\n  ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG -> \"false\"\n)\n\nval consumerStrategy =\n      ConsumerStrategies.Subscribe[String, String](topicsSet, kafkaParams)\nval messages = KafkaUtils.createDirectStream[String, String](\n      ssc,\n      LocationStrategies.PreferConsistent,\n      consumerStrategy)\n\nval lines = messages.map(_.value())\nval words = lines.flatMap(_.split(\" \"))\nval wordCounts = words.map(x => (x, 1L)).reduceByKey(_ + _)\nwordCounts.print()\n\nssc.start()\nssc.awaitTermination()","user":"mapr","dateUpdated":"2019-05-02T05:32:36-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556800196510_1326770881","id":"20190502-052956_500823454","dateCreated":"2019-05-02T05:29:56-0700","dateStarted":"2019-05-02T05:32:37-0700","status":"RUNNING","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:534"},{"text":"%spark\n","user":"mapr","dateUpdated":"2019-05-02T05:32:36-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1556800356975_-2054535176","id":"20190502-053236_1627001835","dateCreated":"2019-05-02T05:32:36-0700","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:535"}],"name":"Consumer for MapR Event Store for Kafka - Spark","id":"2ECQC9UVP","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"sh:shared_process":[],"spark:shared_process":[],"hive:shared_process":[],"livy:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":true,"looknfeel":"default","personalizedMode":"false"},"info":{}}